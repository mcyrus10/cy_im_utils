{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938add65-a782-4394-89d2-3895c0c7fe4d",
   "metadata": {},
   "source": [
    "# CUDA Data Reduction Pipeline\n",
    "\n",
    "[link to ASTRA docs](http://www.astra-toolbox.com/#) (Using version 2.0.0 now)\n",
    "\n",
    "\n",
    "- ~~Rotate at image read~~\n",
    "- ~~%Timeit on vo filter~~\n",
    "- add logging to this\n",
    "- Is GPU attenuation batch function ready to be moved over to cy_im_utils?\n",
    "\n",
    "---\n",
    "\n",
    "### Process Flow\n",
    "\n",
    "0. Dictionary for data set parameters\n",
    "1. (CPU)\n",
    "    - Calculate COR and center the cropping window\n",
    "2. (CPU) Read images $\\rightarrow$ \n",
    "3. Batch (GPU)\n",
    "    - -= df \n",
    "    - /= (ff-df)\n",
    "    - normalize\n",
    "    - spatial (3x3) median (helps with nans)\n",
    "    - Lambert-Beer\n",
    "    - crop\n",
    "4. Batch (GPU)\n",
    "    - Vo\n",
    "5. ASTRA (GPU)\n",
    "\n",
    "\n",
    "---\n",
    "### CUDA notes\n",
    "[link to cuda slides](https://www.nvidia.com/content/GTC-2010/pdfs/2131_GTC2010.pdf)\n",
    "\n",
    "[link to stack overflow](https://stackoverflow.com/questions/4391162/cuda-determining-threads-per-block-blocks-per-gridhttps://stackoverflow.com/questions/4391162/cuda-determining-threads-per-block-blocks-per-grid)\n",
    "> First of all, your thread block size should always be a multiple of 32, because kernels issue instructions in warps (32 threads).\n",
    "\n",
    "[link to nvidia blog post](https://developer.nvidia.com/blog/even-easier-introduction-cuda/)\n",
    "\n",
    "<<<a,b>>> $\\rightarrow$ \n",
    "- a = number of thread blocks\n",
    "- b = threads in a thread block\n",
    "\n",
    "This will execute (add) once per thread rather than spreading hte computation across the parallel threads\n",
    "\n",
    "    add<<<1,256>>>(N,x,y) \n",
    "    \n",
    "> Together, the blocks of parallel threads make up what is known as the *grid*. Since I have N elements to process, and 256 threads per block, I just need to calculate the number of blocks to get at least N threads. I simply divide N by the block size (being careful to round up in case N is not a multiple of blockSize).\n",
    "\n",
    "    int N = 1<<20;\n",
    "    int blockSize = 256;\n",
    "    int numBlocks = (N+blockSize-1) / blockSize;\n",
    "    add<<<numBlocks, blockSize>>>(N,x,y);\n",
    "\n",
    "---\n",
    "\n",
    "## Vo filter settings from Jake (9/21/2021):\n",
    "- remove_all_stripe\n",
    "- snr = 1.5\n",
    "- sm_size = 3\n",
    "- la_size = 85\n",
    "- drop_ratio = default\n",
    "\n",
    "Vo on projection images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d379f0a-d75e-43f9-8894-885fc0495b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sys import path\n",
    "path.append(\"C:\\\\Users\\\\mcd4\\\\Documents\\\\cy_im_utils\")\n",
    "from cy_im_utils.prep import *\n",
    "from cy_im_utils.post import *\n",
    "from cy_im_utils.visualization import *\n",
    "from cy_im_utils.sarepy_cuda import *\n",
    "from cy_im_utils.recon_utils import *\n",
    "path.append(\"C:\\\\Users\\\\mcd4\\\\Documents\\\\vo_filter_source\\\\sarepy\")\n",
    "from sarepy.prep.stripe_removal_original import remove_all_stripe as remove_all_stripe_CPU\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from cupyx.scipy.ndimage import gaussian_filter,rotate as rotate_gpu, median_filter as median_gpu\n",
    "from data_sets import *\n",
    "from glob import glob\n",
    "from ipywidgets import widgets\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from numba import cuda\n",
    "from scipy.ndimage import rotate as rotate_cpu\n",
    "from tqdm import tqdm\n",
    "import astra\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#from scipy.ndimage import median_filter as median_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fbb1a6d-2446-48e0-8189-2080c51ae83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['image.origin'] = 'lower'\n",
    "plt.rcParams['image.cmap'] = 'Spectral'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b247bfab-0928-49dd-9d84-bd6e284d0fe0",
   "metadata": {},
   "source": [
    "### Select Dataset\n",
    "\n",
    "see *data_sets.py* for all current data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59e16a0-543f-411e-830a-e82018bfb091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89345fa4399d4aa18d904a0181d7d50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Select(description='Data Set:', options=(('AAA_bot', {'COR rows': [417, 1632], 'Name': 'AAA_bot', 'Transpose':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_sets = [AAA_bot,MIT,cliffs,granite,ni_cylinders,Pens]\n",
    "data_set_select = widgets.Select(    options=[(d['Name'],d) for d in data_sets],\n",
    "                                     description='Data Set:')\n",
    "display(data_set_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b998db9-799e-4a61-aa3c-c6684db0b77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tData Set\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'COR rows': [235, 1100],\n",
       " 'Name': 'Pens',\n",
       " 'Transpose': False,\n",
       " 'crop patch': [507, 1909, 218, 2491],\n",
       " 'dark path': 'D:\\\\Data\\\\Pens\\\\dark\\\\**.fit',\n",
       " 'dtype': numpy.float32,\n",
       " 'extension': 'fit',\n",
       " 'flat path': 'D:\\\\Data\\\\Pens\\\\flat2\\\\**.fit',\n",
       " 'imread function': <function cy_im_utils.prep.imread_fit(file_name, axis=0, device='gpu', dtype=[<class 'numpy.float32'>, <class 'numpy.float32'>])>,\n",
       " 'norm patch': [216, 602, 359, 1973],\n",
       " 'pixel size': 0.0087,\n",
       " 'projection path': 'D:\\\\Data\\\\Pens\\\\projections\\\\**.fit',\n",
       " 'serialized path': 'D:\\\\Data\\\\serialized_data\\\\recon_volumes\\\\pens_32_bit.p',\n",
       " 'theta': 0.461821941867942}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set = data_set_select.value\n",
    "\n",
    "Transpose = data_set['Transpose']\n",
    "dtype = data_set['dtype']\n",
    "ext = data_set['extension']\n",
    "if ext == 'tif':\n",
    "    read_fcn = Image.open\n",
    "elif ext == 'fit':\n",
    "    read_fcn = imread_fit\n",
    "print(\"\\t\\tData Set\")\n",
    "print(\"-\"*80)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce6dc90-93c1-4d6b-b220-53b95d0f6bc1",
   "metadata": {},
   "source": [
    "### Calculate center of rotation \n",
    "\n",
    "**(PRIOR TO IMPORTING ALL IMAGES)**\n",
    "\n",
    "- $\\checkmark$ ~~Convert this into an interactive function where you can control the cropping, normalization patch, COR coordinates and transpose~~\n",
    "- $\\checkmark$ ~~make this function load in ff and f itself so you can clean it up a bit~~\n",
    "- $\\checkmark$ ~~enforce COR y1 cannot be larger than crop y1 - crop y0~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83554781-ab8d-4d97-a771-f356da700cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 60, 120, 180, 240, 300]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:03,  3.07it/s]\n",
      "10it [00:03,  2.95it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\mcd4\\Documents\\cy_im_utils\\cy_im_utils\\visualization.py:235: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  temp = -np.log((np.asarray(read_fcn(f), dtype = dtype)-df.get())/(ff-df).get())\n",
      "C:\\Users\\mcd4\\Documents\\cy_im_utils\\cy_im_utils\\visualization.py:235: RuntimeWarning: invalid value encountered in true_divide\n",
      "  temp = -np.log((np.asarray(read_fcn(f), dtype = dtype)-df.get())/(ff-df).get())\n",
      "C:\\Users\\mcd4\\Documents\\cy_im_utils\\cy_im_utils\\visualization.py:235: RuntimeWarning: divide by zero encountered in log\n",
      "  temp = -np.log((np.asarray(read_fcn(f), dtype = dtype)-df.get())/(ff-df).get())\n",
      "C:\\Users\\mcd4\\Documents\\cy_im_utils\\cy_im_utils\\visualization.py:235: RuntimeWarning: invalid value encountered in log\n",
      "  temp = -np.log((np.asarray(read_fcn(f), dtype = dtype)-df.get())/(ff-df).get())\n",
      "6it [00:03,  1.76it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "873f165e2fb9415fa4d0c76a3599edcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=0, continuous_update=False, description='crop x0', max=2160), In…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb6000d37ce40fd923409ca3dd0be51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact = True\n",
    "if interact:\n",
    "    d_theta = 60\n",
    "    angles = [j*d_theta for j in range(360//d_theta)]\n",
    "    print(angles)\n",
    "    COR_interact(data_set, angles = angles, figsize = (10,4), cmap = 'gist_ncar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c9c5625-f7df-46ea-8d0b-65c4a4fe0aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_projections(data_dict : dict, dtype = np.float32) -> np.array:\n",
    "    read_fcn = data_dict['imread function']\n",
    "    proj_files = glob(data_dict['projection path'])\n",
    "    n_proj = len(proj_files)\n",
    "    height,width = np.asarray(read_fcn(proj_files[0])).shape\n",
    "    projections = np.zeros([n_proj,height,width], dtype = dtype)\n",
    "    for i in tqdm(range(n_proj)):\n",
    "        projections[i,:,:] = np.asarray(read_fcn(proj_files[i]), dtype = dtype)\n",
    "    return projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f03e53-b890-45a4-ae3e-c773dafe265f",
   "metadata": {},
   "source": [
    "### Read in projection images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5608732-488e-4003-a396-a076fdd40b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:01,  9.08it/s]\n",
      "10it [00:01,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(951, 2160, 2560)\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ff = field_gpu(glob(data_set['flat path']), dtype = dtype)\n",
    "df = field_gpu(glob(data_set['dark path']), dtype = dtype)\n",
    "n_projections = len(glob(data_set['projection path']))\n",
    "Transpose = data_set['Transpose']\n",
    "projections = pickle.load(open(data_set['serialized path'],'rb'))\n",
    "#projections = read_projections(data_set)\n",
    "if Transpose:\n",
    "    projections = np.transpose(projections,(0,2,1))\n",
    "    ff = ff.T\n",
    "    df = df.T\n",
    "print(projections.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a437f70e-4e72-4fd1-ae0e-13bbab879c3d",
   "metadata": {},
   "source": [
    "## GPU Attenuation Batch Loop\n",
    "\n",
    "Testing this with batching numpy: 19.70 seconds per iteration\n",
    "\n",
    "|  | Iterations per second (batch size = 20)| speedup |\n",
    "| ---|--- |---|\n",
    "numpy | .042 |  - |\n",
    "cupy | 0.60 | 14.1 |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90894a77-cd20-4062-9b08-14f4fedd72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attenuation_gpu_batch(input_arr : cp.array, ff : cp.array, df : cp.array ,output_arr : cp.array ,id0 : int,id1 : int,batch_size : int,norm_patch : list,\n",
    "                          crop_patch : list, theta : float, kernel :int = 3, dtype = cp.float32) -> None:\n",
    "    \"\"\"\n",
    "    This is a monster (and probably will need some modifications)\n",
    "    1) upload batch to GPU\n",
    "    2) rotate\n",
    "    3) transpose <------------ NOT NECESSARY SINCE YOU KNOW THE BLOCK STRUCTURE NOW\n",
    "    4) convert image to transmission space\n",
    "    5) extract normalization patches\n",
    "    6) normalize transmission images\n",
    "    7) spatial median (kernel x kernel) -> improves nans when you take -log\n",
    "    8) lambert beer\n",
    "    9) reverse the transpose from 3\n",
    "    10) crop\n",
    "    11) insert batch into output array\n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_arr: 3D numpy array \n",
    "        input volume array\n",
    "    ff: 2D cupy array \n",
    "        flat field\n",
    "    df: 2D cupy array \n",
    "        dark field\n",
    "    output_arr: 3D numpy array \n",
    "        array to output into\n",
    "    id0: int\n",
    "        first index of batch\n",
    "    id1: int\n",
    "        final index of batch\n",
    "    batch_size: int\n",
    "        size of batch\n",
    "    norm_patch: list\n",
    "        list of coordinates of normalization patch (x0,x1,y0,y1)\n",
    "    crop_patch: list\n",
    "        list of coordinates of crop patch (x0,x1,y0,y1)\n",
    "    theta: float\n",
    "        angle to rotate the volume through\n",
    "    kernel: int (odd number)\n",
    "        size of median kernel\n",
    "    dtype: numpy data type\n",
    "        data type of all arrays\n",
    "    \"\"\"\n",
    "    n_proj,height,width = input_arr.shape\n",
    "    projection_gpu = cp.asarray(input_arr[id0:id1], dtype = dtype)\n",
    "    projection_gpu = rotate_gpu(projection_gpu,theta, axes = (1,2), reshape = False)\n",
    "    # uncomment line after for numpy\n",
    "    #projection_gpu = rotate_cpu(projection_gpu,theta, axes = (1,2), reshape = False)\n",
    "    projection_gpu -= df.reshape(1,height,width)\n",
    "    projection_gpu /= (ff-df).reshape(1,height,width)\n",
    "    patch = cp.mean(projection_gpu[:,norm_patch[0]:norm_patch[1],norm_patch[2]:norm_patch[3]], axis = (1,2), dtype = dtype)\n",
    "    projection_gpu /= patch.reshape(batch_size,1,1)\n",
    "    projection_gpu = median_gpu(projection_gpu, (1,kernel,kernel))\n",
    "    # uncomment line after for numpy\n",
    "    #projection_gpu = median_cpu(projection_gpu, (1,kernel,kernel))\n",
    "    \n",
    "    projection_gpu = -cp.log(projection_gpu)\n",
    "    #-----------------------------------------------\n",
    "    #---      make all non-finite values 0?      ---\n",
    "    #-----------------------------------------------\n",
    "    #-----------------------------------------------\n",
    "    projection_gpu[~cp.isfinite(projection_gpu)] = 0\n",
    "    #-----------------------------------------------\n",
    "    #-----------------------------------------------\n",
    "    output_arr[id0:id1] = cp.asnumpy(projection_gpu[:,crop_patch[0]:crop_patch[1],crop_patch[2]:crop_patch[3]])\n",
    "    #output_arr[id0:id1] = projection_gpu[:,crop_patch[0]:crop_patch[1],crop_patch[2]:crop_patch[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07cf3a64-e874-4b52-905c-29b39070ad14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:31<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non finite =  0\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "batch_size = 20\n",
    "#batch_size = 1\n",
    "#=====================================================================================\n",
    "# PROJECTION LOOP (Projections -> Transmission -> Normalize -> Median -> Attenuation)\n",
    "#=====================================================================================\n",
    "# READ PARAMETERS FROM data_set DICT\n",
    "theta = data_set['theta']\n",
    "crop_patch = data_set['crop patch']\n",
    "norm_patch = data_set['norm patch']\n",
    "COR_rows = data_set['COR rows']\n",
    "\n",
    "n_proj,height,width = projections.shape\n",
    "nx = crop_patch[1]-crop_patch[0]\n",
    "ny = crop_patch[3]-crop_patch[2]\n",
    "attn = np.empty([n_proj,nx,ny], dtype = dtype)\n",
    "kernel = 3\n",
    "\n",
    "# For numpy speedup comparison\n",
    "#ff = cp.asnumpy(ff)\n",
    "#df = cp.asnumpy(df)\n",
    "for j in tqdm(range(n_proj//batch_size)):\n",
    "    id0,id1 = j*batch_size,(j+1)*batch_size\n",
    "    attenuation_gpu_batch(projections,ff,df,attn,id0,id1,batch_size,norm_patch,crop_patch, theta , kernel = kernel, dtype = dtype)\n",
    "\n",
    "remainder = n_proj%batch_size\n",
    "attenuation_gpu_batch(projections,ff,df,attn,-remainder,n_proj,remainder,norm_patch,crop_patch, theta , kernel = kernel, dtype = dtype)\n",
    "\n",
    "print(\"non finite = \",np.sum(~np.isfinite(attn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1403674-6a9d-4ae0-a4bc-fd14d4004d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FREE UP MEMORY??\n",
    "#del volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd6a301c-070e-4750-a891-ad71cceac9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8764972948021696 153 1281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c029084aca4afa857e491700cf107b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(theta,COR_rows[0], COR_rows[1])\n",
    "sino_index = 1000\n",
    "combined = attn[0]+attn[n_proj//2]\n",
    "slice_ = combined.T[COR_rows[0]:COR_rows[1]]\n",
    "if np.sum(~np.isfinite(slice_)) > 0:\n",
    "    print(np.sum(~np.isfinite(combined)))\n",
    "    print('nans in region of interest fitting -> can cause SVD to not converge')\n",
    "fig,ax = plt.subplots(2,2, figsize = (10,10))\n",
    "ax = ax.flatten()\n",
    "ax[0].imshow(attn[0,:,:])\n",
    "ax[0].plot([sino_index,sino_index],[0,nx-1],'k--')\n",
    "ax[0].plot([0,ny-1],[nx//2,nx//2],'k--')\n",
    "center_of_rotation(combined.T,COR_rows[0],COR_rows[1],ax[1])\n",
    "ax[2].imshow(attn[:,nx//2,:])\n",
    "ax[3].imshow(attn[:,:,sino_index])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69a1eac4-8b69-474b-a780-0706911a6eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_,ax = plt.subplots(2,1)\n",
    "#ax[0].imshow(projections[:,:,1600])\n",
    "#ax[1].imshow(attn[:,:,1600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a908b-7026-4de3-895b-2019f4a80637",
   "metadata": {},
   "source": [
    "## GPU Sinogram Batch Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea07d8c1-eb3a-402c-984b-8058d60ba6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_cpy = attn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9fd2778-d0bc-4bc3-adee-6685c380c4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attn = cpu_cpy.copy()\n",
    "attn = np.transpose(attn,(0,2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9373c7d-7e14-4ac9-a085-84501a073907",
   "metadata": {},
   "source": [
    "### Sarepy Filter Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d36ff687-d361-4e49-baa0-cf1e628866a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235382d8c1334d3db4b1b08dd9da905d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9476c3ea7e524e62b890a8991b88be94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=0, continuous_update=False, description='row', max=2360), FloatSlider(value=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66a875f58e44a3f80238d3f5b94d9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SAREPY_interact(data_set, attn, figsize = (12,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b717f9-3508-42bb-b96e-7a8e51a9b372",
   "metadata": {},
   "source": [
    "### SAREPY loop\n",
    "\n",
    "Vo_batch is a function that moves batches of sinograms to the gpu, executes the vo filter and moves back to cpu\n",
    "\n",
    "Can this be sped up with multi-threaded pipeline so the copy - process -write structure is handled by one thread each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48f3857c-bca2-4983-bfc1-a5afac2cc4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vo_batch(attenuation : cp.array, dim : int = 1, batch_size : int = 50, \n",
    "             snr : float = 1.5 ,la_size : int = 85, sm_size : int = 3, \n",
    "             in_place : bool = False):\n",
    "    if not in_place:\n",
    "        attenuation = attenuation.copy()\n",
    "        \n",
    "    if dim == 2:\n",
    "        attenuation = np.transpose(attenuation,(0,2,1))\n",
    "        \n",
    "    n_proj,n_row,n_col = attenuation.shape\n",
    "    for j in tqdm(range(n_row//batch_size)):\n",
    "        id0,id1 = j*batch_size, (j+1)*batch_size\n",
    "        vol_gpu = cp.asarray(attenuation[:,id0:id1,:])\n",
    "        vol_gpu = remove_all_stripe_GPU(vol_gpu,snr,la_size,sm_size)\n",
    "        attenuation[:,id0:id1,:] = cp.asnumpy(vol_gpu)\n",
    "\n",
    "    remainder = n_row%batch_size\n",
    "    if remainder > 0:\n",
    "        vol_gpu = cp.asarray(attenuation[:,-remainder:,:])\n",
    "        vol_gpu = remove_all_stripe_GPU(vol_gpu,snr,la_size,sm_size)\n",
    "        attenuation[:,-remainder:,:] = cp.asnumpy(vol_gpu)\n",
    "        \n",
    "    if not in_place:\n",
    "        if dim == 2:\n",
    "            attenuation = np.transpose(attenuation,(0,2,1))\n",
    "        return attenuation\n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb6b7d-ada4-49ac-a2e3-7fc8dcdd0095",
   "metadata": {},
   "source": [
    "### Vo GPU Speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58a23120-e9fc-42c5-9fc7-d21af874a015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [02:22<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "COPY vo_container TO ATTN TO MOVE FORWARD\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#===============================================================================\n",
    "# SINOGRAM LOOP (Vo Filter)\n",
    "#===============================================================================\n",
    "n_proj,n_row,n_col = attn.shape\n",
    "batch_size = 50\n",
    "la_size = data_set['large filter']\n",
    "sm_size = data_set['small filter']\n",
    "snr = data_set['signal to noise ratio']\n",
    "container = None\n",
    "\n",
    "#attn_subset = attn.copy()#[:,::25,:]\n",
    "#print(attn_subset.shape)\n",
    "#vo_container = vo_batch(attn_subset, dim = 2, batch_size = batch_size, snr = snr, la_size = la_size, sm_size = sm_size)\n",
    "vo_container = vo_batch(attn, dim = 1, batch_size = batch_size, snr = snr, la_size = la_size, sm_size = sm_size)\n",
    "#vo_batch(attn, dim = 1, batch_size = batch_size, snr = snr, la_size = la_size, sm_size = sm_size)\n",
    "#container = np.zeros_like(attn)\n",
    "#for j in tqdm(range(n_row)):\n",
    "#    container[:,j,:] = remove_all_stripe_CPU(attn[:,j,:], snr,la_size,sm_size)\n",
    "\n",
    "\n",
    "print(\"-\"*80)\n",
    "print(\"-\"*80)\n",
    "print(\"COPY vo_container TO ATTN TO MOVE FORWARD\")\n",
    "print(\"-\"*80)\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20ae810f-f39d-45d6-8adc-73285e6510c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = vo_container.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0f8420e-b0ed-4557-89fb-0a7835df3049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig,ax = plt.subplots(3,1, figsize = (6,10))\\n#ax = [ax]\\nax[0].imshow(temp[:,0,:])\\nax[1].imshow(filter_cpu)\\nax[2].imshow(filter_cpu-temp[:,0,:])\\nfig.tight_layout()\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "fig,ax = plt.subplots(3,1, figsize = (6,10))\n",
    "#ax = [ax]\n",
    "ax[0].imshow(temp[:,0,:])\n",
    "ax[1].imshow(filter_cpu)\n",
    "ax[2].imshow(filter_cpu-temp[:,0,:])\n",
    "fig.tight_layout()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26f192d1-bd7d-457a-aab3-27268f36881a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421e56e2373a4dfebedb2d87b03796d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sinogram_index = 1600\n",
    "l,h = np.quantile(attn[n_proj//2].flatten(),0.01),np.quantile(attn[n_proj//2].flatten(),0.99)\n",
    "#print(l,h)\n",
    "fig,ax = plt.subplots(3,3, figsize = (8,12))\n",
    "ax[0,0].imshow(attn[n_proj//2,:,:], vmin = l, vmax = h)\n",
    "ax[0,0].set_title(\"Projection\")\n",
    "ax[0,0].plot([nx//2,nx//2],[0,ny-1],'k--')\n",
    "ax[0,0].plot([0,nx-1],[ny//2,ny//2],'k--')\n",
    "ax[1,0].imshow(attn[:,sinogram_index,:].T, vmin = l, vmax = h)\n",
    "ax[1,0].set_title(\"Sinogram (unfiltered)\")\n",
    "ax[2,0].imshow(attn[:,:,n_col//2].T, vmin = l, vmax = h)\n",
    "\n",
    "ax[0,1].imshow(vo_container[n_proj//2,:,:], vmin = l, vmax = h)\n",
    "ax[0,1].set_title(\"Projection\")\n",
    "ax[0,1].plot([nx//2,nx//2],[0,ny-1],'k--')\n",
    "ax[0,1].plot([0,nx-1],[ny//2,ny//2],'k--')\n",
    "ax[1,1].imshow(vo_container[:,sinogram_index,:].T, vmin = l, vmax = h)\n",
    "ax[1,1].set_title(\"Sinogram (filtered)\")\n",
    "ax[2,1].imshow(vo_container[:,:,n_col//2].T, vmin = l, vmax = h)\n",
    "\n",
    "ax[1,2].imshow(remove_all_stripe_CPU(attn[:,sinogram_index,:],snr,la_size,sm_size).T, vmin = l, vmax = h)\n",
    "ax[1,2].set_title(\"Vo CPU (reference)\")\n",
    "\n",
    "ax[0,2].axis('off')\n",
    "ax[2,2].axis('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af281a29-89e3-4eca-837e-9abd8f0ea94d",
   "metadata": {},
   "source": [
    "# ASTRA\n",
    "\n",
    "fbp_cuda_3d: this is very non-optimized but FBP_CUDA does not take 3d geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad91834d-e929-46f2-bd29-2b3708ffacfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSPOSE ATTENUATION ARRAY -> ASTRA takes the sinogram as the first index\n",
    "attn = np.transpose(vo_container,(1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d8a677a-b80d-441d-b4fc-ff1e03b47bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbp_cuda_3d(attn : cp.array, pixel_size : float) -> cp.array:\n",
    "    \"\"\"\n",
    "    naiive implementation of FBP_CUDA on each sinogram individually; not sure why this \n",
    "    isn't in the regular ASTRA configuration for parallel3d.... \n",
    "    Parameters:\n",
    "    ----------\n",
    "    attn: 3d numpy array\n",
    "        attenuation volume\n",
    "        \n",
    "    pixel_size: float\n",
    "        pixel size in mm\n",
    "        \n",
    "    returns:\n",
    "    --------\n",
    "    recon: 3d numpy array\n",
    "        reconstructed volume\n",
    "        \n",
    "    \"\"\"\n",
    "    detector_rows = attn.shape[0]\n",
    "    detector_cols = attn.shape[2]\n",
    "    n_projections = attn.shape[1]\n",
    "    angles = np.linspace(0, 2 * np.pi, num = n_projections, endpoint=False)\n",
    "    recon = np.zeros([detector_rows,detector_cols,detector_cols], dtype = np.float32)\n",
    "    algorithm = 'FBP_CUDA'\n",
    "    for row in tqdm(range(detector_rows)):\n",
    "        proj_geom = astra.create_proj_geom('parallel', 1, detector_cols, angles)\n",
    "        sino_id = astra.data2d.create('-sino', proj_geom, attn[row])\n",
    "        vol_geom = astra.creators.create_vol_geom(detector_cols, detector_cols)\n",
    "        reconstruction_id = astra.data2d.create('-vol', vol_geom)\n",
    "        alg_cfg = astra.astra_dict(algorithm)\n",
    "        alg_cfg['ProjectionDataId'] = sino_id\n",
    "        alg_cfg['ReconstructionDataId'] = reconstruction_id\n",
    "        alg_cfg['option'] = {'FilterType': 'ram-lak'}\n",
    "        algorithm_id = astra.algorithm.create(alg_cfg)\n",
    "        #-------------------------------------------------\n",
    "        astra.algorithm.run(algorithm_id)  # This is slow\n",
    "        #-------------------------------------------------\n",
    "        recon[row] = astra.data2d.get(reconstruction_id)\n",
    "        # DELETE OBJECTS\n",
    "        astra.algorithm.delete(algorithm_id)\n",
    "        astra.data2d.delete([sino_id,reconstruction_id])\n",
    "    return recon/pixel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796727f1-0e00-4c71-bb66-6cb9930fa946",
   "metadata": {},
   "source": [
    "### ASTRA_GENERIC\n",
    "\n",
    "This is just function of convenience to hide some of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f768bdef-cc91-4b9f-a468-8d92ecdc2d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ASTRA_GENERIC(attn : cp.array,geometry : str = 'cone', algorithm : str = 'FDK_CUDA', detector_pixel_size : float = 0.0087, \n",
    "                  source_origin : float = 5965.0, origin_detector : float = 35.0):\n",
    "    \"\"\"\n",
    "    algorithm for cone -> FDK_CUDA\n",
    "    algorithms for Parallel -> SIRT3D_CUDA, FP3D_CUDA, BP3D_CUDA\n",
    "    \"\"\"\n",
    "    detector_rows,n_projections,detector_cols = attn.shape\n",
    "    distance_source_origin = source_origin\n",
    "    distance_origin_detector = origin_detector\n",
    "    angles = np.linspace(0, 2 * np.pi, num = n_projections, endpoint=False)\n",
    "    #  ---------    PARALLEL BEAM    --------------\n",
    "    if geometry.lower() == 'parallel':\n",
    "        proj_geom = astra.create_proj_geom('parallel3d', 1, 1, detector_rows, detector_cols, angles)\n",
    "        projections_id = astra.data3d.create('-sino', proj_geom, attn)\n",
    "    #  ---------    CONE BEAM    --------------\n",
    "    elif geometry.lower() == 'cone':\n",
    "        proj_geom = astra.create_proj_geom('cone', 1, 1, detector_rows, detector_cols, angles,\n",
    "                (distance_source_origin + distance_origin_detector) / detector_pixel_size, 0)\n",
    "        projections_id = astra.data3d.create('-sino', proj_geom, attn)\n",
    "        \n",
    "    vol_geom = astra.creators.create_vol_geom(detector_cols, detector_cols, detector_rows)\n",
    "    reconstruction_id = astra.data3d.create('-vol', vol_geom, data=0)\n",
    "    alg_cfg = astra.astra_dict(algorithm)\n",
    "    alg_cfg['ProjectionDataId'] = projections_id\n",
    "    alg_cfg['ReconstructionDataId'] = reconstruction_id\n",
    "    alg_cfg['option'] = {'FilterType': 'ram-lak'}\n",
    "    algorithm_id = astra.algorithm.create(alg_cfg)\n",
    "    \n",
    "    #-------------------------------------------------\n",
    "    astra.algorithm.run(algorithm_id)  # This is slow\n",
    "    #-------------------------------------------------\n",
    "\n",
    "    reconstruction = astra.data3d.get(reconstruction_id)\n",
    "    reconstruction /= detector_pixel_size\n",
    "\n",
    "    # DELETE OBJECTS TO RELEASE MEMORY\n",
    "    astra.algorithm.delete(algorithm_id)\n",
    "    astra.data2d.delete([projections_id,reconstruction_id])\n",
    "    return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c570f11-5931-4c2d-9fc5-3df87f5cd1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2165/2165 [04:10<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "free = False\n",
    "if free:\n",
    "    del projections         \n",
    "    projections = None\n",
    "fbp = True\n",
    "pixel_size = data_set['pixel size']\n",
    "if fbp:\n",
    "    reconstruction = fbp_cuda_3d(attn, pixel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "292239ca-2318-4d0a-853a-803f43000c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1918\n",
      "932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dacae5497ad450684b9d4841d20bbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ec52a65940>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 4\n",
    "n0 = 840\n",
    "slice_index_x = 932\n",
    "slice_index_y = 500\n",
    "handle = reconstruction[::-1,slice_index_x,:]\n",
    "height,width = handle.shape\n",
    "cmap = 'Spectral'\n",
    "print(width)\n",
    "print(slice_index_x)\n",
    "l,h = nif_99to01contrast(handle[np.isfinite(handle)])\n",
    "#l = -1\n",
    "#h = 1\n",
    "#h = 0.3\n",
    "plt.figure(figsize = (10,20))\n",
    "ax0 = plt.subplot(221)\n",
    "ax0.imshow(handle, vmin = l, vmax = h, cmap = cmap)\n",
    "ax1 = plt.subplot(223)\n",
    "ax1.imshow(reconstruction[::-1,:,slice_index_y], vmin = l, vmax = h, cmap = cmap)\n",
    "dz = height//(n+1)\n",
    "linespec = {\"color\":'k',\"linestyle\":'--',\"linewidth\":1}\n",
    "for j in range(n):\n",
    "    ax0.plot([0,width-1],[dz*(j+1),dz*(j+1)],**linespec)\n",
    "    ax1.plot([0,width-1],[dz*(j+1),dz*(j+1)],**linespec)\n",
    "    a = plt.subplot(n,2,int((j+1)*2))\n",
    "    temp = reconstruction[dz*(j+1),:,:]\n",
    "    #l,h = nif_99to01contrast(temp)\n",
    "    a.imshow(temp.astype(np.float32).T,cmap = cmap, vmin = l, vmax = h)\n",
    "    #a.plot([0,width-1],[slice_index_x,slice_index_x],**linespec)\n",
    "    a.plot([slice_index_x,slice_index_x],[0,width-1],**linespec)\n",
    "    #a.plot([slice_index_y,slice_index_y],[0,width-1],**linespec)\n",
    "    a.plot([0,width-1],[slice_index_y,slice_index_y],**linespec)\n",
    "a.imshow(reconstruction[1051], vmin = l, vmax = h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7443826-2561-43fb-8554-ddffb04c2a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2146/2146 [02:11<00:00, 16.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "to_disk = True\n",
    "if to_disk:\n",
    "    write_dir = f\"D:\\\\Data\\\\Reconstructions\\\\EXPERIMENTATION\\\\{data_set['Name']}\"\n",
    "    write_volume(reconstruction,data_set,write_dir,data_set['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdde371-25ed-4ece-bfa2-576f3f3078ca",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c58d7b4-fbd8-465a-a109-7cc7e500e607",
   "metadata": {},
   "source": [
    "# Scratch Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd518ce5-f961-4df5-ac8a-9934ad1c3b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1737\n",
      "2361\n"
     ]
    }
   ],
   "source": [
    "print(crop_patch[1]-crop_patch[0])\n",
    "print(crop_patch[3]-crop_patch[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe51d9a4-d3e9-4408-a26d-9a7dd4d1decc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COR rows': [256, 1812],\n",
       " 'Name': 'cliffs',\n",
       " 'crop patch': [107, 2025, 215, 2361],\n",
       " 'dark path': 'D:\\\\Data\\\\Calvert_Cliffs_Aggregate\\\\dark\\\\**.fit',\n",
       " 'dtype': numpy.float32,\n",
       " 'extension': 'fit',\n",
       " 'flat path': 'D:\\\\Data\\\\Calvert_Cliffs_Aggregate\\\\flat\\\\**.fit',\n",
       " 'imread function': <function cy_im_utils.prep.imread_fit(file_name, axis=0, device='gpu', dtype=[<class 'numpy.float32'>, <class 'numpy.float32'>])>,\n",
       " 'norm patch': [320, 1804, 2374, 2519],\n",
       " 'pixel size': 0.03,\n",
       " 'projection path': 'D:\\\\Data\\\\Calvert_Cliffs_Aggregate\\\\projections\\\\**.fit',\n",
       " 'serialized path': 'D:\\\\Data\\\\serialized_data\\\\recon_volumes\\\\cliffs_32_bit.p',\n",
       " 'theta': -0.24457877799149086,\n",
       " 'Transpose': False,\n",
       " 'signal to noise ratio': 0.9,\n",
       " 'large filter': 113,\n",
       " 'small filter': 31}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(reconstruction.shape)\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e0b7072e-849e-4931-86d4-60d6cc4dcc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    dump_path = \"D:\\\\Data\\\\serialized_data\\\\cone_beam_prep\\\\{}.p\".format(data_set['Name'])\n",
    "    pickle.dump(attn,open(dump_path,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aff3042-ffdb-4dfc-a68e-f6b9c9144d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "737a11f5-011d-4d28-bbd7-5aca1c2c5409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf638a5d8f649d997f9e1d7947d6b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2266bee20d0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(attn[:,100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2edf340-449f-498d-a978-6f79ca52c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = data_set['Name']\n",
    "file_path = \"D:\\\\Data\\\\sinogram_binaries\"\n",
    "file_name = f'{file_path}\\\\{data_name}.npy'\n",
    "log_file = f'{file_path}\\\\{data_name}.log'\n",
    "np.save(file_name,attn)\n",
    "with open(log_file,'w') as f:\n",
    "    for key,val in data_set.items():\n",
    "        f.write(f\"{key} : {val}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2350c55-848d-461b-a676-6d34597a7891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
